{
  "experiment_id": "bpe_machine_translation_1765355097",
  "config": {
    "tokenizer_type": "bpe",
    "task": "machine_translation",
    "language": "de"
  },
  "tokenizer_vocab_size": 19810,
  "metrics": {
    "bleu_score": 28.422327700733124,
    "inference_speed": 1698.1393949882267,
    "memory_usage": 602.0751549553976
  },
  "tokenization_stats": {
    "avg_tokens_per_sample": 31.105,
    "avg_chars_per_token": 4.087751180917718,
    "max_sequence_length": 106,
    "unk_rate": 0.0,
    "total_tokens": 0
  },
  "training_history": {
    "train_loss": [
      2.319713399228942,
      1.9375146591845598,
      1.9682356070820064,
      1.8460897838524226,
      1.410960909842635,
      1.1093189874018017,
      0.8132679848419317,
      0.9249422188897614,
      0.510220311020348,
      0.6047152283389134
    ],
    "val_loss": [
      2.2125053776113335,
      2.1616053690744117,
      2.238349743711456,
      1.7934694163147082,
      1.6148986097190354,
      1.7026776440516813,
      1.3994188253433246,
      1.4224707403016084,
      1.2946328419379547,
      0.853249379839031
    ],
    "learning_rate": [
      1e-05,
      2e-05,
      3e-05,
      4e-05,
      5e-05,
      5e-05,
      5e-05,
      5e-05,
      5e-05,
      5e-05
    ]
  }
}