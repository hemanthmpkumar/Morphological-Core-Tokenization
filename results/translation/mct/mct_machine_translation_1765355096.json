{
  "experiment_id": "mct_machine_translation_1765355096",
  "config": {
    "tokenizer_type": "mct",
    "task": "machine_translation",
    "language": "de"
  },
  "tokenizer_vocab_size": 17152,
  "metrics": {
    "bleu_score": 29.682862948138663,
    "inference_speed": 1215.9513519186748,
    "memory_usage": 760.9086280308634
  },
  "tokenization_stats": {
    "avg_tokens_per_sample": 53.387,
    "avg_chars_per_token": 2.494543337616199,
    "max_sequence_length": 246,
    "unk_rate": 0.1604323149830483,
    "total_tokens": 0
  },
  "training_history": {
    "train_loss": [
      2.319713399228942,
      1.9375146591845598,
      1.9682356070820064,
      1.8460897838524226,
      1.410960909842635,
      1.1093189874018017,
      0.8132679848419317,
      0.9249422188897614,
      0.510220311020348,
      0.6047152283389134
    ],
    "val_loss": [
      2.2125053776113335,
      2.1616053690744117,
      2.238349743711456,
      1.7934694163147082,
      1.6148986097190354,
      1.7026776440516813,
      1.3994188253433246,
      1.4224707403016084,
      1.2946328419379547,
      0.853249379839031
    ],
    "learning_rate": [
      1e-05,
      2e-05,
      3e-05,
      4e-05,
      5e-05,
      5e-05,
      5e-05,
      5e-05,
      5e-05,
      5e-05
    ]
  }
}